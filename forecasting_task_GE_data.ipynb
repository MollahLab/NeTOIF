{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author: Min Shi\n",
    "## Last updated: 5/18/2021\n",
    "## Description:\n",
    "The code was created to implement the NetOIF model to forecast GE data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from models import gcn, lstm\n",
    "from configs import *\n",
    "from utils import *\n",
    "import scipy.sparse\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the GE data\n",
    "\n",
    "* **`12859_2008_2579_MOESM2_ESM.xls:`** Human estrogen-responsive breast cancer cells expression after 1, 2, 4, 6, 8, 12, 16, 20, 24, 28 and 32 hours hormonal stimulation\n",
    "* **`string_interactions.tsv:`** The protein-protein interaction (PPI) network from stringDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "FLAGS = tf.flags.FLAGS\n",
    "dataset = FLAGS.GE\n",
    "time_steps = 7\n",
    "hidden_dim = 1\n",
    "hidden_size = 1\n",
    "train_ratio = FLAGS.train_ratio\n",
    "window_size = FLAGS.window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_file = os.path.join('datasets/GE', '12859_2008_2579_MOESM2_ESM_processed.xlsx')\n",
    "feat_df = pd.read_excel(feat_file, sheet_name='ZR75.1_QUA_P4_cluster_named').set_index('Search_key')\n",
    "\n",
    "print(feat_df.columns)\n",
    "feats = feat_df.values\n",
    "feats = feats.reshape([feats.shape[0],1,8]).transpose([2, 0, 1])\n",
    "\n",
    "feat_list = []\n",
    "for i in range(time_steps):\n",
    "    feat_list.append(feats[i])\n",
    "\n",
    "protein_names = feat_df.index.tolist()\n",
    "\n",
    "network_file = os.path.join('datasets/GE', 'string_interactions.tsv')\n",
    "net_df = pd.read_csv(network_file,sep='\\t')\n",
    "\n",
    "adj = np.zeros([len(protein_names),len(protein_names)])\n",
    "links = []\n",
    "no_links = []\n",
    "for index, row in net_df.iterrows():\n",
    "    try:\n",
    "        v1_idx = protein_names.index(row['node1'])\n",
    "        v2_idx = protein_names.index(row['node2'])\n",
    "        score = float(row['combined_score'])\n",
    "\n",
    "        adj[v1_idx,v2_idx] = score\n",
    "        adj[v2_idx,v1_idx] = score\n",
    "\n",
    "        links.append((row['node1'], row['node2']))\n",
    "    except:\n",
    "        no_links.append((row['node1'], row['node2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Adjacency matrix:'+str(adj.shape))\n",
    "print('Time series rppa data:'+str(feats.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjs, feats, val_idx, test_idx, protein_names = load_data_prediction_GE(dataset, time_steps, 0.2)\n",
    "\n",
    "\n",
    "print('feats.size:',feats[0].shape)\n",
    "\n",
    "num_node = adjs[0].shape[0]\n",
    "num_feat = feats[0].shape[1]\n",
    "train_idx = np.array(range(num_node))\n",
    "\n",
    "for i in range(time_steps):\n",
    "    adjs[i] = sparse_to_tuple(scipy.sparse.coo_matrix(adjs[i]))\n",
    "#     feats[i] = sparse_to_tuple(scipy.sparse.coo_matrix(feats[i]))\n",
    "num_features_nonzeros = [x[1].shape for x in feats]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(protein_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.9\n",
    "\n",
    "# define placeholders of the input data \n",
    "phs = {\n",
    "        'adjs': [tf.sparse_placeholder(tf.float32, shape=(None, None), name=\"adjs\") for i in\n",
    "             range(time_steps)],\n",
    "        'feats': [tf.placeholder(tf.float32, shape=(None, num_feat), name=\"feats\") for _ in\n",
    "                 range(time_steps)],\n",
    "        'train_idx': tf.placeholder(tf.int32, shape=(None,), name=\"train_idx\"),\n",
    "        'val_idx': tf.placeholder(tf.int32, shape=(None,), name=\"val_idx\"),\n",
    "        'test_idx': tf.placeholder(tf.int32, shape=(None,), name=\"test_idx\"),\n",
    "        'sample_idx': tf.placeholder(tf.int32, shape=(FLAGS.batch_size,), name='batch_sample_idx'),\n",
    "        'dropout_prob': tf.placeholder_with_default(0., shape=()),\n",
    "        'num_features_nonzeros': [tf.placeholder(tf.int64) for i in range(time_steps)]\n",
    "        }\n",
    "\n",
    "# define the GCN model\n",
    "gcn_model = gcn.GraphConvLayer(time_steps = time_steps,\n",
    "                               gcn_layers=FLAGS.gcn_layers,\n",
    "                               input_dim=num_feat,\n",
    "                               hidden_dim=hidden_dim,\n",
    "                               output_dim=hidden_size,\n",
    "                               name='nn_fc1',\n",
    "                               num_features_nonzeros=phs['num_features_nonzeros'],\n",
    "                               act=tf.nn.relu,\n",
    "                               dropout_prob=phs['dropout_prob'],\n",
    "                               dropout=True)\n",
    "embeds_list = gcn_model(adjs=phs['adjs'],\n",
    "                    feats=phs['feats'],\n",
    "                    sparse=False)\n",
    "\n",
    "# prepare train data for the LSTM-based prediction model\n",
    "## replace all missing features at (time_steps-1) with GCN imputed features\n",
    "# embeds_list[time_steps-1] = tf.add(phs['feats'][time_steps-1], \n",
    "#                                    tf.multiply(phs['test_mask'][time_steps-1], embeds_list[time_steps-1]))\n",
    "## construct training samples for the prediction task\n",
    "combined_feats = []\n",
    "for i in range(time_steps):\n",
    "    combined_feats.append(tf.add(alpha*phs['feats'][i], (1-alpha)*embeds_list[i]))\n",
    "\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = build_train_samples_prediction(embeds_list=combined_feats, \n",
    "                                                                                 feats=phs['feats'], \n",
    "                                                                                 time_steps=time_steps,\n",
    "                                                                                 window_size=window_size,\n",
    "                                                                                 val_idx=phs['val_idx'], \n",
    "                                                                                 test_idx=phs['test_idx'])\n",
    "print(\"x_train:\",x_train.shape)\n",
    "print(\"x_val:\",x_val.shape)\n",
    "print(\"x_test:\",x_test.shape)\n",
    "print(\"y_train:\",y_train.shape)\n",
    "print(\"y_val:\",y_val.shape)\n",
    "print(\"y_test:\",y_test.shape)\n",
    "# define the bi-directional LSTM model\n",
    "lstm_model = lstm.BiLSTM(hidden_size=hidden_size,\n",
    "                         seq_len=window_size,\n",
    "                         holders=phs)\n",
    "x_input_seq = tf.gather(x_train, phs['sample_idx'])\n",
    "y_input_seq_real = tf.gather(y_train, phs['sample_idx'])\n",
    "y_input_seq_pred = lstm_model(input_seq=x_input_seq)\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    # calculate the train mse and ad\n",
    "    print(y_input_seq_real.shape)\n",
    "    train_mse = tf.losses.mean_squared_error(y_input_seq_real, y_input_seq_pred)\n",
    "    train_absolute_diff = tf.losses.absolute_difference(y_input_seq_real, y_input_seq_pred)\n",
    "    \n",
    "    # calculate the val mse and ad\n",
    "    val_input_seq_pred = lstm_model(input_seq=x_val)\n",
    "    val_mse = tf.losses.mean_squared_error(y_val, val_input_seq_pred)\n",
    "    val_absolute_diff = tf.losses.absolute_difference(y_val, val_input_seq_pred)\n",
    "    \n",
    "    # calculate the test mse and ad\n",
    "    test_input_seq_pred = lstm_model(input_seq=x_test)\n",
    "    test_mse = tf.losses.mean_squared_error(y_test, test_input_seq_pred)\n",
    "    test_absolute_diff = tf.losses.absolute_difference(y_test, test_input_seq_pred)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)\n",
    "    opt_op = optimizer.minimize(train_mse)\n",
    "\n",
    "n_cpus = 8\n",
    "config = tf.ConfigProto(device_count={ \"CPU\": n_cpus},\n",
    "                            inter_op_parallelism_threads=n_cpus,\n",
    "                            intra_op_parallelism_threads=2)\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "feed_dict = {phs['train_idx']: train_idx,\n",
    "             phs['val_idx']: val_idx,\n",
    "             phs['test_idx']: test_idx,\n",
    "             phs['sample_idx']: None,\n",
    "             phs['dropout_prob']: FLAGS.dropout_prob}\n",
    "\n",
    "feed_dict.update({phs['adjs'][t]: adjs[t] for t in range(time_steps)})\n",
    "feed_dict.update({phs['feats'][t]: feats[t] for t in range(time_steps)})\n",
    "feed_dict.update({phs['num_features_nonzeros'][t]: num_features_nonzeros[t] for t in range(time_steps)})\n",
    "\n",
    "feed_dict_val = {phs['train_idx']: train_idx,\n",
    "                 phs['val_idx']: val_idx,\n",
    "                 phs['test_idx']: test_idx,\n",
    "                 phs['dropout_prob']: 0}\n",
    "\n",
    "feed_dict_val.update({phs['adjs'][t]: adjs[t] for t in range(time_steps)})\n",
    "feed_dict_val.update({phs['feats'][t]: feats[t] for t in range(time_steps)})\n",
    "feed_dict_val.update({phs['num_features_nonzeros'][t]: num_features_nonzeros[t] for t in range(time_steps)})\n",
    "\n",
    "\n",
    "def get_batch_idx(epoch):\n",
    "    s = FLAGS.batch_size * epoch\n",
    "    e = FLAGS.batch_size * (epoch + 1)\n",
    "    idx = []\n",
    "    for i in range(s,e):\n",
    "        idx.append(i%len(train_idx))\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = FLAGS.epochs\n",
    "save_step = 10\n",
    "t = time.time()\n",
    "\n",
    "test_MSEs = []\n",
    "test_ADs = []\n",
    "for k in range(20):\n",
    "    for epoch in range(epochs):\n",
    "        batch_samples = get_batch_idx(epoch)\n",
    "        feed_dict.update({phs['sample_idx']: batch_samples})\n",
    "        _, train_MSE, train_AD = sess.run((opt_op, train_mse, train_absolute_diff), feed_dict=feed_dict)\n",
    "        val_MSE, val_AD, x_val_ = sess.run((val_mse, val_absolute_diff, x_val), \n",
    "                                                                 feed_dict=feed_dict_val) \n",
    "\n",
    "#         print(\"Epoch:\", '%04d' % (epoch + 1),\n",
    "#           \"train_loss=\", \"{:.5f}\".format(train_MSE),\n",
    "#           \"train_MSE=\", \"{:.5f}\".format(train_MSE),\n",
    "#           \"train_AD=\", \"{:.5f}\".format(train_AD),\n",
    "#           \"val_MSE=\", \"{:.5f}\".format(val_MSE),\n",
    "#           \"val_AD=\", \"{:.5f}\".format(val_AD),\n",
    "#           \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "#         if (epoch+1) % save_step == 0:\n",
    "    test_MSE, test_AD, missing_actual_, missing_predicted_ = sess.run((test_mse, test_absolute_diff,\n",
    "                                                                      y_test, test_input_seq_pred), \n",
    "                                                                      feed_dict=feed_dict_val) \n",
    "    print(\"-------test_MSE=\", \"{:.5f}\".format(test_MSE),\n",
    "      \"test_AD=\", \"{:.5f}\".format(test_AD))\n",
    "    \n",
    "    test_MSEs.append(float(test_MSE))\n",
    "    test_ADs.append(float(test_AD))\n",
    "    \n",
    "average_MSE = statistics.mean(test_MSEs)\n",
    "stdev_MSE = statistics.stdev(test_MSEs)\n",
    "average_AD = statistics.mean(test_ADs)\n",
    "stdev_AD = statistics.stdev(test_ADs)\n",
    "print('average_MSE=%f, stdev_MSE=%f, average_AD=%f, stdev_AD=%f' % (average_MSE, stdev_MSE,\n",
    "                                                                      average_AD, stdev_AD))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as plticker\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "protein_names = np.array(protein_names)\n",
    "\n",
    "protein_names_test = np.array(protein_names[test_idx])\n",
    "\n",
    "fig = plt.figure(figsize=(3,6))\n",
    "fig.subplots_adjust(hspace=0, wspace=2.4)\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.set_aspect('auto')\n",
    "cax1 = ax1.matshow(missing_actual_,cmap='bwr',norm = colors.DivergingNorm(vcenter=0), aspect=\"auto\")\n",
    "fig.colorbar(cax1, pad=0.2)\n",
    "ax1.set_title('Actual_28h',y=-0.1)\n",
    "\n",
    "loc = plticker.MultipleLocator(base=20) # this locator puts ticks at regular intervals\n",
    "ax1.yaxis.set_major_locator(loc)\n",
    "show_protein_names = protein_names_test[range(0, len(protein_names_test), 10)]\n",
    "\n",
    "ax1.set_yticks(range(len(protein_names_test)))\n",
    "loc = plticker.MultipleLocator(base=20) # this locator puts ticks at regular intervals\n",
    "ax1.yaxis.set_major_locator(loc)\n",
    "show_protein_names = protein_names_test[range(0, len(protein_names_test), 10)]\n",
    "show_protein_names = np.insert(show_protein_names, 0, 0, axis=0)\n",
    "ax1.set_yticklabels(show_protein_names, fontsize=11)\n",
    "ax1.set_xticks([])\n",
    "\n",
    "\n",
    "fig1 = plt.figure(figsize=(3,6))\n",
    "fig1.subplots_adjust(hspace=0, wspace=2.4)\n",
    "\n",
    "ax2 = fig1.add_subplot(122)\n",
    "ax2.set_aspect('auto')\n",
    "cax2 = ax2.matshow(missing_predicted_,cmap='bwr',norm = colors.DivergingNorm(vcenter=0), aspect=\"auto\")\n",
    "fig1.colorbar(cax2, pad=0.2)\n",
    "ax2.set_title('Imputed_28h',y=-0.1)\n",
    "\n",
    "ax2.set_yticks(range(len(protein_names_test)))\n",
    "ax2.yaxis.set_major_locator(loc)\n",
    "ax2.set_yticklabels(show_protein_names, fontsize=11)\n",
    "# ax2.set_xticklabels('1', fontsize=11)\n",
    "ax2.set_xticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
